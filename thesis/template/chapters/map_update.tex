\chapter{Map Update}
\label{chapter:map_update}

Dieses Kapitel basiert auf den Ausführungen in Kapitel \ref{chapter:association}. Dabei wurde herausgestellt, dass ein Update der Karte ohne eine zusätzliche Datenbasis in der Nachbehandlung aufgrund einer Vielzahl an Problemen nicht möglich ist. Im Folgenden wird das Problem auf der um die Menge an Punktwolken $\mathbb{C}$ erweiterten Datenbasis neu betrachtet. Dabei wird das Problem selbst neu aufgerollt. Anstelle in einem fertigen Pose-Graphen wie in Kapitel \ref{chapter:loop_closure} beschrieben nach Schleifenschlüssen zu suchen, den Graphen auf Basis der identifizierten Schleifenschlüsse zu optimieren und darauf beruhend ein Update auf einer bereits fertigen Karte durchzuführend wird nun ein inkrementelles Vorgehen angestrebt. Ziel ist die Möglichkeit zu bieten, den Ansatz in einen existierenden, auf einer TSDF-Karte beruhenden, SLAM-Algorithmus zu integrieren. In einer Nachbearbeitung ist es nicht zwingend notwendig die Karte nach jedem identifizierten Schleifenschluss und der darauf beruhenden Graph-Optimierung ein Update der Karte durchzuführend, da die TSDF-Karte selbst für den vorgestellten Optimierungsprozess, der auf den Punktwolken $\mathbb{C}$ beruht, nicht benötigt wird. Innerhalb eines auf der TSDF-Karte operierenden SLAM-Ansatzes wie \cite{HATSDF} ist es allerdings unerlässlich, dass die Karte in jedem Inkrement auf dem neusten Stand ist um eine konsistente Registrierung neuer Daten an die Karte gewährleisten zu können.

Um dieses Ziel zu erreichen, muss nach jedem Inkrement in dem eine Graph-Optimierung vorgenommen wurde ein Update der bisher erstellten Karte durchgeführt werden. Da eine sichere und lückenlose Ermittlung von Datenassoziationen basierend auf den Posen $\mathbb{P}$ und der TSDF-Karte nicht ohne weiteres möglich ist, ist an dieser Stelle eine andere Herangehensweise an das Problem des Updates gefragt. In einem ersten Schritt wird hier ein \textbf{Greedy (gierig)}-Ansatz gewählt. Ziel eines solchen Ansatzes ist ein Problem auf eine möglichst einfache Weise zu lösen und dabei längere Laufzeiten der gefundenen Lösung in Kauf zu nehmen. Eine möglichst einfache Lösung beim Update der Karte besteht darin zunächst vollständig auf lokale Updates zu verzichten und stattdessen die gesamte Karte zu löschen und neu zu generieren. Dies ist bezogen auf die Laufzeit besonders bei großen Datensätzen keine gute Idee, da auch Teile der Karte vollständig gelöscht und neu generiert werden, die keines Updates bedürfen. Aus diesem Grund wird im weiteren Verlauf dieses Kapitel zusätzlich auf ein partielles, lokales Update der Karte eingegangen und die benötigten Voraussetzungen und Fallstricke beschrieben. Ziel ist hier eine erhebliche Reduktion der Laufzeit. Zunächst wird im folgenden Abschnitt auf das beschriebene globale Update eingegangen.

\section{Globales Update}
\label{section:global_update}

Dieser Abschnitt befasst sich mit dem beschriebenen Greedy-Ansatz zur Lösung des Kartenupdates. Ziel ist das Löschen der gesamten TSDF-Karte und die nachfolgende Regeneration der Karte basierend auf der erweiterten Datenbasis. Im ersten Schritt wird betrachtet, wie die Karte am effizientesten gelöscht werden kann. Hier lohnt sich eine Betrachtung des Datenflusses zwischen der lokalen und globalen Karte. Dieser wurde in Kapitel \ref{chapter:grundlagen} bereits kurz angeschnitten. Die globale Karte kapselt die Funktionalität zur Serialisierung und Deserialisierung von Daten basierend auf der HDF5-Datei als Speichermedium. Die globale Karte tauscht die benötigten Daten Chunk weise mit der HDF5 aus. Jeder Chunk beinhaltet eine fest definierte Anzahl an TSDF-Gewichten und zugehörigen Werten und deckt einen vorgegebenen Bereich der globalen Karte ab, der über den Index des Chunks definiert ist. Die lokale Karte ist ein 3D Fenster mit vorgegebenen Seitenlängen, welches den aktuell betrachteten Teil der globalen Karte enthält und über die globale Karte wandern kann. Die lokale Karte liefert dabei eine Abstraktion zur globalen Karte. Grundsätzlich werden neue Daten nur über die lokale Karte geschrieben und schlussendlich an die globale Karte zurückgeliefert, die diese gegebenenfalls serialisiert. Dieses Konstrukt sorgt für eine geringe Auslastung des Arbeitsspeichers, da immer nur ein Teil der gesamten Karte aus der HDF5 geladen wird. Die Abstraktion über die lokale ist sinnvoll, da in der Regel nur einzelne TSDF-Zellen beschrieben werden. An dieser Stelle ist es allerdings von Nöten, dass alle Chunks der globalen Karte gelöscht werden, beziehungsweise die enthaltenen Daten mit Default-Werten ersetzt werden. HDF5 erlaubt zwar ein Löschen einzelner Datensätze (in diesem Fall Chunks), dies gibt allerdings nicht den von dem Datensatz beanspruchten Speicher wieder frei. Dies sorgt dafür, dass die Karte bei einer Löschung aller Datensätze und der darauf folgenden Regeneration der Karte und Chunks auf Basis des neuen Pose-Graphen stetig wächst. Das Beschreiben aller TSDF-Zellen über die Abstraktion der lokalen Karte ist zusätzlich keine gute Idee, da dies hohe Laufzeiten durch eine große Anzahl von Schreibbefehlen und mehrere Verschiebungen (\textbf{Shifts}) der lokalen Karte zur Folge hat. Aus diesem Grund wird an dieser Stelle auf die Abstraktion der lokalen Karte verzichtet und innerhalb der globalen Karte eine Methode entwickelt, die alle Chunks auf ihren Ursprungszustand zurücksetzt und mit Default-Werten füllt. Diese Methode ist um ein Vielfaches schneller als das Zurücksetzen der Karte über die Abstraktion der lokalen Karte und die damit verbundenen, benötigten Shifts der lokalen Karte. Doch auch diese Methode sorgt gegebenenfalls für leere Chunks, die nie zur Verwendung kommen, aber Speicher einnehmen. Eine drastische, aber auch schnellere Lösung ist das Löschen der gesamten HDF5 und der anschließenden Neuerstellung der Datei unter demselben Namen mit identischen Metadaten. \improvement{ggf. erklären, dass auch das wegen HDF5 nicht geht, weil die Dateien nicht geschlossen werden und auch manuell nicht geschlossen werden können}

Im Anschluss an die Neuerstellung der HDF5 gilt es nun, die Karte auf Basis des neuen Pfades $\mathfrak{P}_{new}$ zu regenerieren. Dazu ist keine Berechnung der Transformationen zwischen altem und neuen Pfad oder eine Transformation der zu den Posen zugehörigen Punktwolken notwendig, da die Punktwolken jeweils relativ zu den Posen gesehen werden und entsprechend relative Punktkoordinaten enthalten. Es ist für jede Pose, beginnend bei der ersten Pose des neuen Pfades, ein Shift der lokalen Karte zur aktuellen Pose und darauf folgend ein TSDF-Update basierend auf der zugehörigen Punktwolke durchzuführen. Für genanntes TSDF-Update wird hier wieder die Abstraktion über die lokale Karte verwendet. Dies ist zur Veranschaulichung als Pseudo-Code in Abbildung \ref{pseudo:global_update} dargestellt.

\begin{algorithm}[H]
\caption{Globales TSDF-Kartenupdate} \label{pseudo:global_update}
\begin{algorithmic}[1]
\Procedure{GlobalUpdate}{ $map_{global}, map_{local}, \mathfrak{P}_{new}, \mathbb{C}$ }
	\State Lösche die zu $map_{global}$ zugehörige HDF5
	\State Regeneriere besagte HDF5 mit identischen Metadaten
	\For{$P_i$ in $\mathfrak{P}_{new}$}
		\State Verschiebe $map_{local}$ nach $P_i$
		\State Führe ein TSDF-Update basierend auf $P_i$ und der zugehörigen Punktwolke $C_i$ aus
		\State Schreibe die Daten aus $map_{local}$ zurück in $map_{global}$
	\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

Dieses Update sorgt für eine konsistente Karte entsprechend des neuen Pfades, ist aber aufgrund des Löschens und Regenerierens von Daten die keiner Regeneration bedürften sehr Laufzeit intensiv. Dies ist besonders bei großen Umgebungen mit vielen Posen merklich. Besonders vor dem Hintergrund der für einen Shift der lokalen Karte benötigten Laufzeit von häufig mehr als einer Sekunde, abhängig von der Kartengröße der Größe des betroffenen Bereichs. Um diese hohe Laufzeit zu reduzieren und nur den Teil der Karte zu Updaten, der von den Optimierungen des Pose-Graphen betroffen ist, wird im Folgenden auf ein partielles Update eingegangen. 


\section{Partielles Update}
\label{section:partial_update}

Dieser Absatz befasst sich mit einem partiellen Karten-Update der durch Optimierungen am Pose-Graphen betroffenen Teilbereiche der TSDF-Karte. Dazu gilt es zunächst die Teile der Karte zu bestimmten, die ein genanntes Update benötigen.

----------------------
WIP

erste Herangehenweise: ähnlich wie bei globalem Update, aber: nur TSDF für Posen löschen, die um einen Abstand X bzw. einen Winkel Y verschoben wurden. Problem: welche Zellen müssen gelöscht werden, wenn Pose X um $\delta x$ verschoben wurde? Erste Idee: Ray-Tracing ausgehend von X, getroffene Zellen löschen, die zu einem Update gehören (TODO: wie definiert man das überhaupt?).

\section{Pseudocode}

\section{Evaluation}

Vergleich zwischen den Laufzeiten der beiden Updates, z.B. anhand Hannover1 DS (Gesamtlaufzeit), Vergleich mit 
